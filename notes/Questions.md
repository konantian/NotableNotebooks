---
title: Questions
tags: [Notebooks/Cmput 496]
created: '2019-04-10T20:06:43.150Z'
modified: '2019-04-12T04:31:57.560Z'
favorited: true
pinned: true
---

# Questions
1. Why tree is easiest for search and DCG hardest, how about DAG?

2. Reasons for using DAG instead of DCG and tree?

3. Always interger komi in Go?

4. Why different sequences, different states in tree model are duplication?

5. Why single path to each node is advantage?

6. Why dependencies are needed except tree?

7. Is the percentage of program that is speeded up before optimize or after?

8. In winning stratey, in our turn, how to detect which is a winning move and which is not? Just consider one move or as well as the future?

9. Given candidate minimax value m, in what kind of situations we need only one search?

10. Why alphabeta_depth_limited_tictactoe_test.py is blind search?

11. For PV, if there exist two proof trees, is that guaranted that there exist at least one intersection node for both proof trees?

12. Perfomance of minmax compare to negamax and Alphabeta?

13. Tree estimates is exact at depth 0 ... 5?

14. DAG: No savings at lower levels?

15. Massive savings deeper in DAG, why ?

16. IF strongest move is tried first, alphabeta or negamax, which is more effective?

17. Why depth-limited search need evaluation function?

18. Why winning strategy does not have to include a move for every state in current play's turn?

19. IS that true that every state in state space has a proof tree or disproof tree?

20. What's the mean of variance and bias in monto carlo simulations?

21. Why using random simulaitons is much less natural and it still works well on games without chance element?

22. Why shuffle once is not enough in Go?

23. In depth-limited search, how heuristic evaluation funciton works?

24. Why Sim(1000) can have better performance than perfect in TictacToe? How about other games?

25. Why deterministic simulations are not better than random one?

